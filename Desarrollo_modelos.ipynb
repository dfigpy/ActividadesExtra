{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "46de0bec-cfea-4325-9f1c-f337bf29765e",
      "metadata": {
        "id": "46de0bec-cfea-4325-9f1c-f337bf29765e"
      },
      "source": [
        "# Detector de imagenes (Fumadores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7acddd-9130-4d24-bc44-00dd823bdbbb",
      "metadata": {
        "id": "7e7acddd-9130-4d24-bc44-00dd823bdbbb"
      },
      "source": [
        "## Importación del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c7683d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7683d6f",
        "outputId": "e1872615-1e24-45db-cf44-f935a3032ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ],
      "source": [
        "!apt-get install unrar\n",
        "!pip install rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "87f040e1-2a7b-4720-9aef-8c071948ff8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87f040e1-2a7b-4720-9aef-8c071948ff8c",
        "outputId": "1abf115e-a0d9-48f1-87f6-72c0b323b3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-25 03:08:56--  https://github.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/raw/refs/heads/main/recursos/dataset.rar\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/refs/heads/main/recursos/dataset.rar [following]\n",
            "--2025-03-25 03:08:57--  https://raw.githubusercontent.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/refs/heads/main/recursos/dataset.rar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65567508 (63M) [application/octet-stream]\n",
            "Saving to: ‘dataset.rar’\n",
            "\n",
            "dataset.rar         100%[===================>]  62.53M   161MB/s    in 0.4s    \n",
            "\n",
            "2025-03-25 03:08:57 (161 MB/s) - ‘dataset.rar’ saved [65567508/65567508]\n",
            "\n",
            "Archivo descomprimido correctamente.\n"
          ]
        }
      ],
      "source": [
        "import rarfile\n",
        "\n",
        "rarfile.UNRAR_TOOL = \"/usr/bin/unrar\"\n",
        "!wget https://github.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/raw/refs/heads/main/recursos/dataset.rar\n",
        "\n",
        "rar_path = \"/content/dataset.rar\"  # Ruta del archivo RAR\n",
        "extract_path = \"dataset\"  # Carpeta de salida\n",
        "\n",
        "with rarfile.RarFile(rar_path) as rar_ref:\n",
        "    rar_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Archivo descomprimido correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8dd5744-c4c5-4783-868f-d974aea7d221",
      "metadata": {
        "id": "f8dd5744-c4c5-4783-868f-d974aea7d221"
      },
      "source": [
        "## Entrenamiento de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0440ec21",
      "metadata": {
        "id": "0440ec21"
      },
      "source": [
        "### SVC - Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b96c30df",
      "metadata": {
        "id": "b96c30df"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91cc9d82",
      "metadata": {
        "id": "91cc9d82"
      },
      "source": [
        "#### Tratamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225f1f92",
      "metadata": {
        "id": "225f1f92"
      },
      "outputs": [],
      "source": [
        "# Función para cargar las imagenes desde el folder y almacenarlas en forma de vector númerico, junto con otro array con su clasificación\n",
        "def svc_loadImages(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = Image.open(os.path.join(folder, filename)).convert(\"L\")\n",
        "        img = img.resize((250,250))\n",
        "        img_array = np.array(img).flatten()\n",
        "        images.append(img_array)\n",
        "        label = 0 if \"notsmoking\" in filename else 1 # Si el nombre de la imagen es 'notsmoking' colocar 0, caso contrario 1\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2afe626",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2afe626",
        "outputId": "c5139b05-7e50-4670-fc81-8bba5cf1ee9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de entrenamiento: 716\tPorcentaje: 63.93\n",
            "Datos de validación: 180\tPorcentaje: 16.07\n",
            "Datos de prueba: 224\t\tPorcentaje: 20.00\n"
          ]
        }
      ],
      "source": [
        "#Separacion imagenes train y test\n",
        "scv_Xtrain, svc_ytrain = svc_loadImages(\"dataset/dataset/Training\")\n",
        "svc_Xval, svc_yval = svc_loadImages(\"dataset/dataset/Validation\")\n",
        "svc_Xtest, svc_ytest = svc_loadImages(\"dataset/dataset/Testing\")\n",
        "\n",
        "print(f\"Datos de entrenamiento: {len(scv_Xtrain)}\\tPorcentaje: {(len(scv_Xtrain)*100/1120):.2f}\")\n",
        "print(f\"Datos de validación: {len(svc_Xval)}\\tPorcentaje: {(len(svc_Xval)*100/1120):.2f}\")\n",
        "print(f\"Datos de prueba: {len(svc_Xtest)}\\t\\tPorcentaje: {(len(svc_Xtest)*100/1120):.2f}\")\n",
        "\n",
        "\n",
        "#Escalado de imagenes con StandarScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scv_Xtrain_st = scaler.fit_transform(scv_Xtrain)\n",
        "scv_Xval_st = scaler.transform(svc_Xval)\n",
        "scv_Xtest_st = scaler.transform(svc_Xtest)\n",
        "\n",
        "scv_Xtrain[:2], scv_Xtrain_st[:2]\n",
        "\n",
        "\n",
        "#Reducir dimensionalidad con PCA a 90 componentes (componentes originales = 250)\n",
        "pca = PCA(n_components=90)\n",
        "\n",
        "scv_Xtrain_pca = pca.fit_transform(scv_Xtrain_st)\n",
        "scv_Xval_pca = pca.transform(scv_Xval_st)\n",
        "scv_Xtest_pca = pca.transform(scv_Xtest_st)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8752c327",
      "metadata": {
        "id": "8752c327"
      },
      "source": [
        "#### Entrenamiento del modelo svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1ce007",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1ce007",
        "outputId": "25b5e7cf-b5f1-47e0-b247-258f96182b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Puntuación del mejor modelo: 0.77\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "svm = SVC(kernel=\"linear\", random_state=42)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "best_score = -np.inf\n",
        "best_model = None\n",
        "\n",
        "# Realizar validación cruzada\n",
        "for train_idx, val_idx in cv.split(scv_Xtrain_pca, svc_ytrain):\n",
        "    X_train_fold, X_val_fold = scv_Xtrain_pca[train_idx], scv_Xtrain_pca[val_idx]\n",
        "    y_train_fold, y_val_fold = svc_ytrain[train_idx], svc_ytrain[val_idx]\n",
        "\n",
        "\n",
        "    svm.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    score = svm.score(X_val_fold, y_val_fold)\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_model = SVC(kernel=\"linear\", random_state=42)\n",
        "        best_model.fit(scv_Xtrain_pca, svc_ytrain)\n",
        "\n",
        "# Porcenaje final\n",
        "print(f\"Puntuación del mejor modelo: {best_score:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64759500",
      "metadata": {
        "id": "64759500"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "40f80d26",
      "metadata": {
        "id": "40f80d26"
      },
      "source": [
        "#### Exportación de recursos (modelo, scaler, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5815dac5",
      "metadata": {
        "id": "5815dac5"
      },
      "outputs": [],
      "source": [
        "# Código"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a7ca25",
      "metadata": {
        "id": "09a7ca25"
      },
      "source": [
        "### MobileNetV2 (CNN) (keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d6497b51",
      "metadata": {
        "id": "d6497b51"
      },
      "outputs": [],
      "source": [
        "#algunas importacione\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5287521c",
      "metadata": {
        "id": "5287521c"
      },
      "source": [
        "Pre-procesamiento de la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "24bae4b0",
      "metadata": {
        "id": "24bae4b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cd5335-56d6-48f0-858b-71835bd47c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 574 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#en construcion#####\n",
        "# shutil.rmtree(\"/content/dataset/dataset/training\")\n",
        "\n",
        "ruta_origen = \"dataset/dataset/Training\"\n",
        "ruta_smoking = \"dataset/dataset/training/smoking\"\n",
        "ruta_notsmoking = \"dataset/dataset/training/notsmoking\"\n",
        "\n",
        "os.makedirs(ruta_smoking, exist_ok=True)\n",
        "os.makedirs(ruta_notsmoking, exist_ok=True)\n",
        "\n",
        "for archivo in os.listdir(ruta_origen):\n",
        "  if os.path.isfile(os.path.join(ruta_origen, archivo)):\n",
        "    if \"notsmoking\" not in archivo.lower() :\n",
        "      shutil.move(os.path.join(ruta_origen, archivo), os.path.join(ruta_notsmoking, archivo))\n",
        "    elif(True):\n",
        "      shutil.move(os.path.join(ruta_origen, archivo), os.path.join(ruta_smoking, archivo))\n",
        "\n",
        "datadir = \"/content/dataset/dataset/training\"\n",
        "imgsize = (250, 250)\n",
        "batchsize = (32)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale= 1/255, validation_split=0.2)\n",
        "\n",
        "train_data = datagen.flow_from_directory(datadir,target_size=imgsize,\n",
        "                                         batch_size=batchsize,class_mode='binary',subset='training')\n",
        "val_data = datagen.flow_from_directory(datadir,target_size=imgsize,\n",
        "                                       batch_size=batchsize,class_mode='binary',subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12191fb7",
      "metadata": {
        "id": "12191fb7"
      },
      "source": [
        "Instanciación del modelo (preentrenado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "159d71b6",
      "metadata": {
        "id": "159d71b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643cda81-b43b-4736-94fd-35e30844652b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-5544de3839aa>:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  mnet = keras.applications.MobileNetV2(input_shape=(250, 250, 3), include_top=False, weights='imagenet',classifier_activation=\"softmax\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 550ms/step - accuracy: 0.5802 - loss: 0.7956 - val_accuracy: 0.7958 - val_loss: 0.4869\n",
            "Epoch 2/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8307 - loss: 0.3932 - val_accuracy: 0.8028 - val_loss: 0.4290\n",
            "Epoch 3/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 0.8924 - loss: 0.2828 - val_accuracy: 0.8521 - val_loss: 0.4421\n",
            "Epoch 4/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9067 - loss: 0.2399 - val_accuracy: 0.8380 - val_loss: 0.3817\n",
            "Epoch 5/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.9152 - loss: 0.1961 - val_accuracy: 0.8239 - val_loss: 0.3964\n",
            "Epoch 6/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 0.9463 - loss: 0.1550 - val_accuracy: 0.8380 - val_loss: 0.4349\n",
            "Epoch 7/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.9565 - loss: 0.1244 - val_accuracy: 0.8169 - val_loss: 0.4854\n",
            "Epoch 8/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9495 - loss: 0.1499 - val_accuracy: 0.8169 - val_loss: 0.4785\n",
            "Epoch 9/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.9922 - loss: 0.0851 - val_accuracy: 0.8310 - val_loss: 0.4580\n",
            "Epoch 10/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9938 - loss: 0.0580 - val_accuracy: 0.8521 - val_loss: 0.4152\n",
            "Epoch 11/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9932 - loss: 0.0489 - val_accuracy: 0.8169 - val_loss: 0.4440\n",
            "Epoch 12/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 129ms/step - accuracy: 0.9976 - loss: 0.0343 - val_accuracy: 0.8380 - val_loss: 0.4605\n",
            "Epoch 13/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 0.9971 - loss: 0.0334 - val_accuracy: 0.8239 - val_loss: 0.4590\n",
            "Epoch 14/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0296 - val_accuracy: 0.8310 - val_loss: 0.4538\n",
            "Epoch 15/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.8310 - val_loss: 0.4737\n",
            "Epoch 16/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.8239 - val_loss: 0.4680\n",
            "Epoch 17/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.8239 - val_loss: 0.4829\n",
            "Epoch 18/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0168 - val_accuracy: 0.8169 - val_loss: 0.4865\n",
            "Epoch 19/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.9984 - loss: 0.0132 - val_accuracy: 0.8239 - val_loss: 0.5095\n",
            "Epoch 20/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8239 - val_loss: 0.5022\n",
            "Epoch 21/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.8099 - val_loss: 0.5126\n",
            "Epoch 22/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.8310 - val_loss: 0.4978\n",
            "Epoch 23/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.8451 - val_loss: 0.5112\n",
            "Epoch 24/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.8380 - val_loss: 0.5220\n",
            "Epoch 25/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.8380 - val_loss: 0.5187\n",
            "Epoch 26/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8239 - val_loss: 0.5216\n",
            "Epoch 27/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.8380 - val_loss: 0.5348\n",
            "Epoch 28/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.8380 - val_loss: 0.5375\n",
            "Epoch 29/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8310 - val_loss: 0.5516\n",
            "Epoch 30/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.8380 - val_loss: 0.5543\n",
            "Epoch 31/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8380 - val_loss: 0.5505\n",
            "Epoch 32/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8310 - val_loss: 0.5747\n",
            "Epoch 33/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8380 - val_loss: 0.5682\n",
            "Epoch 34/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.8310 - val_loss: 0.5573\n",
            "Epoch 35/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8380 - val_loss: 0.5767\n",
            "Epoch 36/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8380 - val_loss: 0.5821\n",
            "Epoch 37/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8310 - val_loss: 0.5783\n",
            "Epoch 38/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8380 - val_loss: 0.5980\n",
            "Epoch 39/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8380 - val_loss: 0.5878\n",
            "Epoch 40/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8380 - val_loss: 0.6023\n",
            "Epoch 41/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8380 - val_loss: 0.6243\n",
            "Epoch 42/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8380 - val_loss: 0.6302\n",
            "Epoch 43/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8451 - val_loss: 0.5998\n",
            "Epoch 44/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8380 - val_loss: 0.6255\n",
            "Epoch 45/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8380 - val_loss: 0.6073\n",
            "Epoch 46/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8380 - val_loss: 0.6361\n",
            "Epoch 47/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8380 - val_loss: 0.6316\n",
            "Epoch 48/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8310 - val_loss: 0.6544\n",
            "Epoch 49/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8310 - val_loss: 0.6199\n",
            "Epoch 50/50\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8451 - val_loss: 0.6138\n"
          ]
        }
      ],
      "source": [
        "mnet = keras.applications.MobileNetV2(input_shape=(250, 250, 3), include_top=False, weights='imagenet',classifier_activation=\"softmax\")\n",
        "mnet.trainable = False\n",
        "\n",
        "model = keras.Sequential([\n",
        "    mnet,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Clasificación binaria\n",
        "])\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, validation_data=val_data, epochs=50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}