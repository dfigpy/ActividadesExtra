{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "46de0bec-cfea-4325-9f1c-f337bf29765e",
      "metadata": {
        "id": "46de0bec-cfea-4325-9f1c-f337bf29765e"
      },
      "source": [
        "# Detector de imagenes (Fumadores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7acddd-9130-4d24-bc44-00dd823bdbbb",
      "metadata": {
        "id": "7e7acddd-9130-4d24-bc44-00dd823bdbbb"
      },
      "source": [
        "## Importación del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c7683d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7683d6f",
        "outputId": "e1872615-1e24-45db-cf44-f935a3032ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unrar is already the newest version (1:6.1.5-1ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        }
      ],
      "source": [
        "!apt-get install unrar\n",
        "!pip install rarfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "87f040e1-2a7b-4720-9aef-8c071948ff8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87f040e1-2a7b-4720-9aef-8c071948ff8c",
        "outputId": "1abf115e-a0d9-48f1-87f6-72c0b323b3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-25 03:08:56--  https://github.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/raw/refs/heads/main/recursos/dataset.rar\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/refs/heads/main/recursos/dataset.rar [following]\n",
            "--2025-03-25 03:08:57--  https://raw.githubusercontent.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/refs/heads/main/recursos/dataset.rar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65567508 (63M) [application/octet-stream]\n",
            "Saving to: ‘dataset.rar’\n",
            "\n",
            "dataset.rar         100%[===================>]  62.53M   161MB/s    in 0.4s    \n",
            "\n",
            "2025-03-25 03:08:57 (161 MB/s) - ‘dataset.rar’ saved [65567508/65567508]\n",
            "\n",
            "Archivo descomprimido correctamente.\n"
          ]
        }
      ],
      "source": [
        "import rarfile\n",
        "\n",
        "rarfile.UNRAR_TOOL = \"/usr/bin/unrar\"\n",
        "!wget https://github.com/repositoriosHackaton/SIC25es-Remember-Us-Recuerdanos-/raw/refs/heads/main/recursos/dataset.rar\n",
        "\n",
        "rar_path = \"/content/dataset.rar\"  # Ruta del archivo RAR\n",
        "extract_path = \"dataset\"  # Carpeta de salida\n",
        "\n",
        "with rarfile.RarFile(rar_path) as rar_ref:\n",
        "    rar_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Archivo descomprimido correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8dd5744-c4c5-4783-868f-d974aea7d221",
      "metadata": {
        "id": "f8dd5744-c4c5-4783-868f-d974aea7d221"
      },
      "source": [
        "## Entrenamiento de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0440ec21",
      "metadata": {
        "id": "0440ec21"
      },
      "source": [
        "### SVC - Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b96c30df",
      "metadata": {
        "id": "b96c30df"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91cc9d82",
      "metadata": {
        "id": "91cc9d82"
      },
      "source": [
        "#### Tratamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "225f1f92",
      "metadata": {
        "id": "225f1f92"
      },
      "outputs": [],
      "source": [
        "# Función para cargar las imagenes desde el folder y almacenarlas en forma de vector númerico, junto con otro array con su clasificación\n",
        "def svc_loadImages(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = Image.open(os.path.join(folder, filename)).convert(\"L\")\n",
        "        img = img.resize((250,250))\n",
        "        img_array = np.array(img).flatten()\n",
        "        images.append(img_array)\n",
        "        label = 0 if \"notsmoking\" in filename else 1 # Si el nombre de la imagen es 'notsmoking' colocar 0, caso contrario 1\n",
        "        labels.append(label)\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2afe626",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2afe626",
        "outputId": "c5139b05-7e50-4670-fc81-8bba5cf1ee9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos de entrenamiento: 716\tPorcentaje: 63.93\n",
            "Datos de validación: 180\tPorcentaje: 16.07\n",
            "Datos de prueba: 224\t\tPorcentaje: 20.00\n"
          ]
        }
      ],
      "source": [
        "#Separacion imagenes train y test\n",
        "scv_Xtrain, svc_ytrain = svc_loadImages(\"dataset/dataset/Training\")\n",
        "svc_Xval, svc_yval = svc_loadImages(\"dataset/dataset/Validation\")\n",
        "svc_Xtest, svc_ytest = svc_loadImages(\"dataset/dataset/Testing\")\n",
        "\n",
        "print(f\"Datos de entrenamiento: {len(scv_Xtrain)}\\tPorcentaje: {(len(scv_Xtrain)*100/1120):.2f}\")\n",
        "print(f\"Datos de validación: {len(svc_Xval)}\\tPorcentaje: {(len(svc_Xval)*100/1120):.2f}\")\n",
        "print(f\"Datos de prueba: {len(svc_Xtest)}\\t\\tPorcentaje: {(len(svc_Xtest)*100/1120):.2f}\")\n",
        "\n",
        "\n",
        "#Escalado de imagenes con StandarScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scv_Xtrain_st = scaler.fit_transform(scv_Xtrain)\n",
        "scv_Xval_st = scaler.transform(svc_Xval)\n",
        "scv_Xtest_st = scaler.transform(svc_Xtest)\n",
        "\n",
        "scv_Xtrain[:2], scv_Xtrain_st[:2]\n",
        "\n",
        "\n",
        "#Reducir dimensionalidad con PCA a 90 componentes (componentes originales = 250)\n",
        "pca = PCA(n_components=90)\n",
        "\n",
        "scv_Xtrain_pca = pca.fit_transform(scv_Xtrain_st)\n",
        "scv_Xval_pca = pca.transform(scv_Xval_st)\n",
        "scv_Xtest_pca = pca.transform(scv_Xtest_st)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8752c327",
      "metadata": {
        "id": "8752c327"
      },
      "source": [
        "#### Entrenamiento del modelo svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1ce007",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1ce007",
        "outputId": "25b5e7cf-b5f1-47e0-b247-258f96182b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Puntuación del mejor modelo: 0.77\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "svm = SVC(kernel=\"linear\", random_state=42)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "best_score = -np.inf\n",
        "best_model = None\n",
        "\n",
        "# Realizar validación cruzada\n",
        "for train_idx, val_idx in cv.split(scv_Xtrain_pca, svc_ytrain):\n",
        "    X_train_fold, X_val_fold = scv_Xtrain_pca[train_idx], scv_Xtrain_pca[val_idx]\n",
        "    y_train_fold, y_val_fold = svc_ytrain[train_idx], svc_ytrain[val_idx]\n",
        "\n",
        "\n",
        "    svm.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Evaluar el modelo\n",
        "    score = svm.score(X_val_fold, y_val_fold)\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_model = SVC(kernel=\"linear\", random_state=42)\n",
        "        best_model.fit(scv_Xtrain_pca, svc_ytrain)\n",
        "\n",
        "# Porcenaje final\n",
        "print(f\"Puntuación del mejor modelo: {best_score:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64759500",
      "metadata": {
        "id": "64759500"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "40f80d26",
      "metadata": {
        "id": "40f80d26"
      },
      "source": [
        "#### Exportación de recursos (modelo, scaler, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5815dac5",
      "metadata": {
        "id": "5815dac5"
      },
      "outputs": [],
      "source": [
        "# Código"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a7ca25",
      "metadata": {
        "id": "09a7ca25"
      },
      "source": [
        "### MobileNetV2 (CNN) (keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d6497b51",
      "metadata": {
        "id": "d6497b51"
      },
      "outputs": [],
      "source": [
        "#algunas importacione\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5287521c",
      "metadata": {
        "id": "5287521c"
      },
      "source": [
        "Pre-procesamiento de la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "24bae4b0",
      "metadata": {
        "id": "24bae4b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf2cb13-8e85-4f92-b5f8-cefbe1b7d4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 574 images belonging to 2 classes.\n",
            "Found 142 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "#en construcion#####\n",
        "# shutil.rmtree(\"/content/dataset/dataset/training\")\n",
        "\n",
        "ruta_origen = \"dataset/dataset/Training\"\n",
        "ruta_smoking = \"dataset/dataset/training/smoking\"\n",
        "ruta_notsmoking = \"dataset/dataset/training/notsmoking\"\n",
        "\n",
        "os.makedirs(ruta_smoking, exist_ok=True)\n",
        "os.makedirs(ruta_notsmoking, exist_ok=True)\n",
        "\n",
        "for archivo in os.listdir(ruta_origen):\n",
        "  if os.path.isfile(os.path.join(ruta_origen, archivo)):\n",
        "    if \"notsmoking\" not in archivo.lower() :\n",
        "            shutil.move(os.path.join(ruta_origen, archivo), os.path.join(ruta_notsmoking, archivo))\n",
        "    elif(True):\n",
        "            shutil.move(os.path.join(ruta_origen, archivo), os.path.join(ruta_smoking, archivo))\n",
        "\n",
        "\n",
        "datadir = \"/content/dataset/dataset/training\"\n",
        "imgsize = (224, 224)\n",
        "batchsize = (32)\n",
        "\n",
        "datagen = ImageDataGenerator(rescale= 1/255, validation_split=0.2)\n",
        "\n",
        "train_data = datagen.flow_from_directory(datadir,target_size=imgsize,\n",
        "                                         batch_size=batchsize,class_mode='binary',subset='training')\n",
        "val_data = datagen.flow_from_directory(datadir,target_size=imgsize,\n",
        "                                       batch_size=batchsize,class_mode='binary',subset='validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12191fb7",
      "metadata": {
        "id": "12191fb7"
      },
      "source": [
        "Instanciación del modelo (preentrenado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "159d71b6",
      "metadata": {
        "id": "159d71b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f972ece-26f1-40d2-dd2b-7547da43bde2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 519ms/step - accuracy: 0.6096 - loss: 0.6437 - val_accuracy: 0.8028 - val_loss: 0.4196\n",
            "Epoch 2/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.8726 - loss: 0.3021 - val_accuracy: 0.7958 - val_loss: 0.4341\n",
            "Epoch 3/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.9167 - loss: 0.2437 - val_accuracy: 0.8239 - val_loss: 0.3773\n",
            "Epoch 4/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9399 - loss: 0.1871 - val_accuracy: 0.8169 - val_loss: 0.4542\n",
            "Epoch 5/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9461 - loss: 0.1592 - val_accuracy: 0.8310 - val_loss: 0.3999\n",
            "Epoch 6/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.9539 - loss: 0.1321 - val_accuracy: 0.8099 - val_loss: 0.4985\n",
            "Epoch 7/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9615 - loss: 0.1184 - val_accuracy: 0.8310 - val_loss: 0.3971\n",
            "Epoch 8/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 0.9899 - loss: 0.0877 - val_accuracy: 0.8310 - val_loss: 0.4137\n",
            "Epoch 9/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.9836 - loss: 0.0548 - val_accuracy: 0.8380 - val_loss: 0.4081\n",
            "Epoch 10/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 133ms/step - accuracy: 0.9877 - loss: 0.0623 - val_accuracy: 0.8380 - val_loss: 0.3915\n",
            "Epoch 11/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.9972 - loss: 0.0417 - val_accuracy: 0.8451 - val_loss: 0.4791\n",
            "Epoch 12/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0278 - val_accuracy: 0.8521 - val_loss: 0.4586\n",
            "Epoch 13/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.9977 - loss: 0.0227 - val_accuracy: 0.8380 - val_loss: 0.4452\n",
            "Epoch 14/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.9991 - loss: 0.0314 - val_accuracy: 0.8380 - val_loss: 0.4189\n",
            "Epoch 15/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.9958 - loss: 0.0226 - val_accuracy: 0.8451 - val_loss: 0.4298\n",
            "Epoch 16/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.8521 - val_loss: 0.4334\n",
            "Epoch 17/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.8451 - val_loss: 0.4650\n",
            "Epoch 18/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.8521 - val_loss: 0.4624\n",
            "Epoch 19/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.8451 - val_loss: 0.4750\n",
            "Epoch 20/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.8310 - val_loss: 0.4762\n",
            "Epoch 21/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.8592 - val_loss: 0.4923\n",
            "Epoch 22/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.8521 - val_loss: 0.5088\n",
            "Epoch 23/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.8451 - val_loss: 0.5245\n",
            "Epoch 24/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.8380 - val_loss: 0.4977\n",
            "Epoch 25/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.8592 - val_loss: 0.5129\n",
            "Epoch 26/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8451 - val_loss: 0.5394\n",
            "Epoch 27/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8310 - val_loss: 0.5548\n",
            "Epoch 28/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.8521 - val_loss: 0.5295\n",
            "Epoch 29/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.8592 - val_loss: 0.5024\n",
            "Epoch 30/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.8592 - val_loss: 0.5260\n",
            "Epoch 31/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.8380 - val_loss: 0.5835\n",
            "Epoch 32/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8592 - val_loss: 0.5318\n",
            "Epoch 33/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8592 - val_loss: 0.5302\n",
            "Epoch 34/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8592 - val_loss: 0.5452\n",
            "Epoch 35/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8521 - val_loss: 0.5578\n",
            "Epoch 36/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8662 - val_loss: 0.5406\n",
            "Epoch 37/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8451 - val_loss: 0.5367\n",
            "Epoch 38/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8662 - val_loss: 0.5593\n",
            "Epoch 39/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8592 - val_loss: 0.5644\n",
            "Epoch 40/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8521 - val_loss: 0.5537\n",
            "Epoch 41/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.8521 - val_loss: 0.5925\n",
            "Epoch 42/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.8592 - val_loss: 0.5854\n",
            "Epoch 43/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.8521 - val_loss: 0.5992\n",
            "Epoch 44/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8521 - val_loss: 0.6082\n",
            "Epoch 45/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8662 - val_loss: 0.6048\n",
            "Epoch 46/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8451 - val_loss: 0.6111\n",
            "Epoch 47/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.8521 - val_loss: 0.6052\n",
            "Epoch 48/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8451 - val_loss: 0.6346\n",
            "Epoch 49/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8380 - val_loss: 0.6272\n",
            "Epoch 50/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8380 - val_loss: 0.6122\n",
            "Epoch 51/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8380 - val_loss: 0.6182\n",
            "Epoch 52/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8521 - val_loss: 0.6201\n",
            "Epoch 53/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8380 - val_loss: 0.6322\n",
            "Epoch 54/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.8521 - val_loss: 0.6089\n",
            "Epoch 55/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8521 - val_loss: 0.6224\n",
            "Epoch 56/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8662 - val_loss: 0.6171\n",
            "Epoch 57/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8592 - val_loss: 0.6128\n",
            "Epoch 58/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 8.9597e-04 - val_accuracy: 0.8662 - val_loss: 0.6269\n",
            "Epoch 59/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 8.8623e-04 - val_accuracy: 0.8592 - val_loss: 0.6224\n",
            "Epoch 60/60\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 9.3731e-04 - val_accuracy: 0.8592 - val_loss: 0.6262\n"
          ]
        }
      ],
      "source": [
        "mnet = keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet',classifier_activation=\"softmax\")\n",
        "mnet.trainable = False\n",
        "\n",
        "model = keras.Sequential([\n",
        "    mnet,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Clasificación binaria\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, validation_data=val_data, epochs=60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}